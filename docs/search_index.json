[
["testing.html", "Chapter 6 Advanced: Testing code 6.1 Console tests 6.2 In-script testing 6.3 Formalise testing", " Chapter 6 Advanced: Testing code From a coding point of view, testing covers the requirements spelled out in the Verification pillar of the QA framework. Note that testing does not overlap with the Validation QA pillar: it is concerned with code running properly rather than with the adequacy of model assumptions. Testing is a vast topic and it is beyond the scope of this guide to explore it in depth. Here we concentrate on broad principles corresponding to incrementally thorough testing. These ways of testing include: console tests in-script testing formalised testing procedures, as are applied in software development unit testing (tests the different components or “units” of code using tools such as testthat in R) integration testing (tests the correct flow of data through the components) system testing (tests the overall outputs make sense) acceptance testing (tests whether or not the work meets its objectives) 6.1 Console tests Testing code within the R console is not recommended as it leaves no trace or records of what has been checked. 6.2 In-script testing In-script testing is sufficient to facilitate QA in most cases, although tests should always be accompanied by brief comments signalling their presence and indicating what they are evaluating and what the expected output should be. For a quality assurer, running these tests ensures that the entire analytical workflow is reproducible. In R there are many ways to perform in-script checks, from print() statements, to base functions stop() and stopfinot(), to functions from dedicated packages such as assertthat or testit. Examples are shown below. # This code snippet creates a function that # returns the maximum value of a vector # of numbers. The function contains # an in-script test checking that # its input is numerical. If the condition # is not met, execution is halted get_max &lt;- function(x) { stopifnot(is.numeric(x)) max(x) } get_max(c(1:10)) # returns 10 get_max(c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;)) # returns error message # Error in get_max(c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;)) : is.numeric(x) is not TRUE 6.3 Formalise testing Beyond in-script tests, an analyst may decide to take a more formal approach to testing if the project warrants it, this is commonly referred to as ‘unit testing’. These require both writing tests in separate files and using specialised packages that run all tests at once and return success/failure feedback. The testthat package is a popular tool to write and run tests in R (more details here). Although most of its documentation and functionalities focus on testing in the context of package writing, testthat can also be used with regular R projects. There’s a brief overview of unit testing below, but for a more detailed introduction see here or here for a more in-depth overview of automated testing, including test driven development. In testthat, tests are called expectations. These spell out the expected behaviour of a specific piece of code - typically a function. testthat provides many functionalities to define expectations - see details here. Expectations falling within a same testing context are stored in a same file and all testing files are saved within a dedicated testing directory. Below is an example of a file containing tests checking data integrity. # This file is stored in a directory called &quot;testing_directory&quot; # Define context context(&quot;checking data integrity&quot;) # The first test checks that the data set # &quot;mydata&quot; has a a single column and 100 rows test_that(&#39;data dimensions correct&#39;, { expect_equal(ncol(mydata), 1) expect_equal(nrow(mydata), 100) }) # The second test checks that the maximum value # of the variable &quot;some_numbers&quot; does not exceed 1 test_that(&#39;no value greater than 1&#39;, { expect_lt(max(mydata$some_numbers), 1) }) Expectations are tested using the test_dir() function, which takes the path to the testing directory as an argument. library(testthat) library(tidyverse) # create a data frame mydata &lt;- tibble(some_numbers = runif(100)) # test expectations and examine outputs # In this case, all tests are OK test_dir(&quot;testing_directory&quot;) test_dir() provides detailed outputs, including a time line of success/failure and any warnings that may have occured. "]
]
